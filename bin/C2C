#!/usr/bin/env python
import argparse
import logging
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 
import sys
from time import perf_counter
from time import time
from pathlib import Path

import h5py
import pandas as pd
import silx.io.dictdump as sio
from keras import backend as K
from tqdm import tqdm
import numpy as np
import dosma as dm
from pydicom.filereader import read_file_meta_info, dcmread
from glob import glob

sys.path.append("/dataNAS/people/lblankem/abCTSeg")

from abctseg.data import Dataset, predict
from abctseg.models import Models
from abctseg.preferences import PREFERENCES, reset_preferences, save_preferences
from abctseg.run import compute_results, find_files, format_output_path, get_dicom_paths
from abctseg.utils import dl_utils
from abctseg.utils import spine_utils
from abctseg.utils.logger import setup_logger
from abctseg.nn_unet import spine_seg
from abctseg.inference_2d import inference_2d
from abctseg.utils.visualization import save_binary_segmentation_overlay, generate_panel
from abctseg import metrics


os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"

def setup(args):
    """Load preferences and perform basic setups."""
    args_dict = vars(args)
    config_file = args.config_file if "config_file" in args_dict else None
    if config_file:
        PREFERENCES.merge_from_file(args.config_file)
    opts = args.opts
    if len(opts) and opts[0] == "--":
        opts = opts[1:]
    PREFERENCES.merge_from_list(opts)
    setup_logger(PREFERENCES.CACHE_DIR)


def add_config_file_argument(parser: argparse.ArgumentParser):
    parser.add_argument(
        "--config-file",
        type=str,
        required=False,
        help="Preferences config file",
    )


def add_opts_argument(parser: argparse.ArgumentParser):
    parser.add_argument(
        "opts",
        help="Modify preferences options using the command-line",
        default=None,
        nargs=argparse.REMAINDER,
    )


def argument_parser():
    parser = argparse.ArgumentParser("abCTSeg command line interface")
    subparsers = parser.add_subparsers(dest="action")

    # Processing parser
    process_parser = subparsers.add_parser("process", help="process abCT scans")
    process_parser.add_argument(
        "--dicoms",
        nargs="+",
        type=str,
        required=True,
        help="path to dicom files(s)/directories to segment.",
    )
    process_parser.add_argument(
        "--max-depth",
        nargs="?",
        type=str,
        default=None,
        help="max depth to search directory. Default: None (recursive search)",
    )
    process_parser.add_argument(
        "--pattern",
        nargs="?",
        type=str,
        default=None,
        help="regex pattern for file names. Default: None",
    )
    process_parser.add_argument(
        "--overwrite",
        action="store_true",
        help="overwrite results for computed files. Default: False",
    )
    process_parser.add_argument(
        "--num-gpus",
        default=1,
        type=int,
        help="number of GPU(s) to use. Defaults to cpu if no gpu found.",
    )
    process_parser.add_argument(
        "--models",
        nargs="+",
        required=True,
        type=str,
        choices=[x.model_name for x in Models],
        help="models to use for inference",
    )
    process_parser.add_argument(
        "--batch", action="store_true", help="run in batch mode"
    )
    process_parser.add_argument(
        "--pp",
        action="store_true",
        help="use post-processing. Will be used for all specified models.",
    )

    add_config_file_argument(process_parser)
    add_opts_argument(process_parser)

    process_3d_parser = subparsers.add_parser("process_3d", help="process abCT dicom series")

    process_3d_parser.add_argument(
        "--pp",
        action="store_true",
        help="use post-processing. Will be used for all specified models.",
    )

    process_3d_parser.add_argument(
        "--models",
        default = ["stanford_v0.0.1"],
        type=str,
        choices=[x.model_name for x in Models],
        help="models to use for inference",
    )
    
    process_3d_parser.add_argument(
        "--num-gpus",
        default=1,
        type=int,
        help="number of GPU(s) to use. Defaults to cpu if no gpu found.",
    )

    process_3d_parser.add_argument(
        "--batch", action="store_true", help="run in batch mode"
    )

    add_config_file_argument(process_3d_parser)
    add_opts_argument(process_3d_parser)

    # summarize parser.
    summarize_parser = subparsers.add_parser(
        "summarize", help="summarize results"
    )
    summarize_parser.add_argument(
        "--results-dir",
        "--results-path",
        required=True,
        help="path to results directory",
    )
    add_config_file_argument(summarize_parser)
    add_opts_argument(summarize_parser)

    # init parser.
    cfg_parser = subparsers.add_parser("config", help="init abCTSeg library")
    init_subparsers = cfg_parser.add_subparsers(
        title="config sub-commands", dest="cfg_action"
    )
    init_subparsers.add_parser("ls", help="list default preferences config")
    init_subparsers.add_parser("reset", help="reset to default config")
    save_cfg_parser = init_subparsers.add_parser(
        "save", help="set config defaults"
    )
    add_config_file_argument(save_cfg_parser)
    add_opts_argument(save_cfg_parser)

    return parser


def handle_init(args):
    cfg_action = args.cfg_action
    if cfg_action == "ls":
        print("\n" + PREFERENCES.dump())
    elif cfg_action == "reset":
        print("\nResetting preferences...")
        reset_preferences()
        save_preferences()
        print("\n" + PREFERENCES.dump())
    elif cfg_action == "save":
        setup(args)
        save_preferences()
        print("\nUpdated Preferences:")
        print("====================")
        print(PREFERENCES.dump())
    else:
        raise AssertionError("cfg_action {} not supported".format(cfg_action))


def handle_process(args):
    setup(args)
    if not PREFERENCES.MODELS_DIR:
        raise ValueError(
            "MODELS_DIR not initialized. "
            "Use `C2C config` to set MODELS_DIR"
        )
    logger = logging.getLogger("abctseg.cli.__main__")
    logger.info("\n\n======================================================")
    gpus = dl_utils.get_available_gpus(args.num_gpus)
    num_gpus = len(gpus) if gpus is not None else 0
    if gpus is not None:
        os.environ["CUDA_VISIBLE_DEVICES"] = ",".join([str(x) for x in gpus])
    else:
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # cpu

    # Find files.
    files = []
    dirs = []
    for f in args.dicoms:
        if os.path.isfile(f):
            files.append(f)
        elif os.path.isdir(f):
            dirs.append(os.path.abspath(f))
            
    files.extend(
        find_files(
            dirs,
            max_depth=args.max_depth,
            exist_ok=args.overwrite,
            pattern=args.pattern,
        )
    )

    logger.info("{} scans found".format(len(files)))
    if len(files) == 0:
        sys.exit(0)

    batch_size = PREFERENCES.BATCH_SIZE
    use_pp = args.pp
    num_workers = PREFERENCES.NUM_WORKERS
    dataset = Dataset(files, windows=model_type.windows)

    logger.info("Preferences:\n" + PREFERENCES.dump())

    inference_2d(args, dataset, batch_size, use_pp, num_workers, files, num_gpus)
    

def handle_process_3d(args):
    st = time()
    setup(args)
    if not PREFERENCES.MODELS_DIR:
        raise ValueError(
            "MODELS_DIR not initialized. "
            "Use `C2C config` to set MODELS_DIR"
        )
    logger = logging.getLogger("abctseg.cli.__main__")
    logger.info("\n\n======================================================")

    gpus = dl_utils.get_available_gpus(args.num_gpus)
    num_gpus = len(gpus) if gpus is not None else 0
    if gpus is not None:
        os.environ["CUDA_VISIBLE_DEVICES"] = ",".join([str(x) for x in gpus])
    else:
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"  
    logger.info("Preferences:\n" + PREFERENCES.dump())

    seg_input_path = PREFERENCES.INPUT_DIR
    segmentations_path = Path(PREFERENCES.OUTPUT_DIR) / "segmentations"
    segmentations_path.mkdir(parents=True, exist_ok=True)
    seg_output_dir = str(segmentations_path / "spine.nii.gz")

    # Perform spine segmentation inference
    seg, mvs = spine_seg(logger, seg_input_path, seg_output_dir)
    dicom_files, label_text, centroids = spine_utils.find_spine_dicoms(seg)
    logger.info("{} scans found".format(len(dicom_files)))
    spine_utils.visualize_coronal_sagittal_spine(seg, mvs, centroids, label_text, PREFERENCES.OUTPUT_DIR)

    # Print dicom paths to logger
    logger.info(f"Dicom paths: {dicom_files}")
    batch_size = PREFERENCES.BATCH_SIZE
    use_pp = args.pp
    num_workers = PREFERENCES.NUM_WORKERS
    (inputs, masks, file_names) = inference_2d(args, batch_size, use_pp, num_workers, dicom_files, num_gpus, logger, label_text)

    df, manifest = handle_summarize(PREFERENCES.OUTPUT_DIR)
    figure_text_map = metrics.manifest_to_map(manifest)

    # Save images
    for num_2d in range(len(inputs)):
        save_binary_segmentation_overlay(inputs[num_2d], masks[num_2d], PREFERENCES.OUTPUT_DIR, f"{file_names[num_2d]}.png", figure_text_key = figure_text_map)
    generate_panel(os.path.join(PREFERENCES.OUTPUT_DIR, "images"))
    end = time()

    # Log total time for 3d processing
    logger.info(f"Total time for 3D processing: {end-st:.2f}s.")

def handle_summarize(results_dir):
    results_dir_sub = Path(results_dir) / "metrics"
    results_dir_sub.mkdir(exist_ok=True)
    metrics_file = os.path.join(results_dir_sub, "abct-metrics.csv")
    h5_files = sorted(
        find_files(results_dir, pattern=".*h5$", exist_ok=True)
    )

    manifest = []
    for h5_file in tqdm(h5_files, desc="Parsing metrics"):
        with h5py.File(h5_file, "r") as f:
            for model in f.keys():
                scalar_metrics = {}
                for tissue in f[model]:
                    h5_group = f[model][tissue]
                    scalar_metrics.update(
                        {
                            f"{metric} ({tissue})": h5_group[metric][()]
                            for metric in h5_group
                            if not h5_group[metric].shape
                        }
                    )

                manifest.append(
                    {"File": h5_file, "Model": model, **scalar_metrics}
                )

    df = pd.DataFrame(manifest)
    df.to_csv(metrics_file, index=False)
    return df, manifest


def main():
    args = argument_parser().parse_args()
    if args.action == "config":
        handle_init(args)
    elif args.action == "process":
        handle_process(args)
    elif args.action == "process_3d":
        handle_process_3d(args)
    elif args.action == "summarize":
        handle_summarize(args)
    else:
        raise AssertionError("{} command not supported".format(args.action))


if __name__ == "__main__":
    main()