#!/usr/bin/env python
import argparse
import logging
import os
import sys
from pathlib import Path
from time import time
import shutil

import h5py
import pandas as pd

# import voxel as vx
from tqdm import tqdm

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

from comp2comp import metrics
from comp2comp.inference_2d import inference_2d
from comp2comp.models import Models
from comp2comp.nn_unet import spine_seg
from comp2comp.preferences import PREFERENCES, reset_preferences, save_preferences
from comp2comp.run import find_files, get_dicom_paths_and_num, get_file_names
from comp2comp.utils import dl_utils, spine_utils
from comp2comp.utils.logger import setup_logger
from comp2comp.utils.visualization import (
    generate_panel,
    save_binary_segmentation_overlay,
)

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"


def setup(args):
    """Load preferences and perform basic setups.
    
    Args:
        args (argparse.Namespace): command line arguments.
    """
    args_dict = vars(args)
    config_file = args.config_file if "config_file" in args_dict else None
    if config_file:
        PREFERENCES.merge_from_file(args.config_file)
    opts = args.opts
    if len(opts) and opts[0] == "--":
        opts = opts[1:]
    PREFERENCES.merge_from_list(opts)
    setup_logger(PREFERENCES.CACHE_DIR)


def add_config_file_argument(parser: argparse.ArgumentParser):
    parser.add_argument(
        "--config-file",
        type=str,
        required=False,
        help="Preferences config file",
    )


def add_opts_argument(parser: argparse.ArgumentParser):
    parser.add_argument(
        "opts",
        help="Modify preferences options using the command-line",
        default=None,
        nargs=argparse.REMAINDER,
    )


def argument_parser():
    parser = argparse.ArgumentParser("abCTSeg command line interface")
    subparsers = parser.add_subparsers(dest="action")

    # Processing parser
    process_2d_parser = subparsers.add_parser("process_2d", help="process abCT scans")

    process_2d_parser.add_argument(
        "--pp",
        action="store_false",
        help="use post-processing.",
    )
    process_2d_parser.add_argument(
        "--max-depth",
        nargs="?",
        type=str,
        default=None,
        help="max depth to search directory. Default: None (recursive search)",
    )
    process_2d_parser.add_argument(
        "--pattern",
        nargs="?",
        type=str,
        default=None,
        help="regex pattern for file names. Default: None",
    )
    process_2d_parser.add_argument(
        "--overwrite",
        action="store_true",
        help="overwrite results for computed files. Default: False",
    )
    process_2d_parser.add_argument(
        "--num-gpus",
        default=1,
        type=int,
        help="number of GPU(s) to use. Defaults to cpu if no gpu found.",
    )
    process_2d_parser.add_argument(
        "--muscle_fat_model",
        default = 'stanford_v0.0.1',
        type=str,
        help="muscle + fat segmentation model to use for inference",
    )

    add_config_file_argument(process_2d_parser)
    add_opts_argument(process_2d_parser)

    process_3d_parser = subparsers.add_parser("process_3d",
                                              help="process abCT dicom series")
    process_3d_parser.add_argument(
        "--pp",
        action="store_false",
        help="use post-processing.",
    )
    process_3d_parser.add_argument(
        "--muscle_fat_model",
        default="stanford_v0.0.1",
        type=str,
        help="muscle + fat segmentation model to use for inference",
    )
    process_3d_parser.add_argument(
        "--num-gpus",
        default=1,
        type=int,
        help="number of GPU(s) to use. Defaults to cpu if no gpu found.",
    )

    add_config_file_argument(process_3d_parser)
    add_opts_argument(process_3d_parser)

    # summarize parser.
    summarize_parser = subparsers.add_parser(
        "summarize", help="summarize results"
    )
    summarize_parser.add_argument(
        "--results-dir",
        "--results-path",
        required=True,
        help="path to results directory",
    )
    add_config_file_argument(summarize_parser)
    add_opts_argument(summarize_parser)

    # init parser.
    cfg_parser = subparsers.add_parser("config", help="init abCTSeg library")
    init_subparsers = cfg_parser.add_subparsers(
        title="config sub-commands", dest="cfg_action"
    )
    init_subparsers.add_parser("ls", help="list default preferences config")
    init_subparsers.add_parser("reset", help="reset to default config")
    save_cfg_parser = init_subparsers.add_parser(
        "save", help="set config defaults"
    )
    add_config_file_argument(save_cfg_parser)
    add_opts_argument(save_cfg_parser)

    return parser


def handle_init(args):
    """Handle init command.
    
    Args:
        args (argparse.Namespace): command line arguments.

    Raises:
        ValueError: if invalid config action.
    """
    cfg_action = args.cfg_action
    if cfg_action == "ls":
        print("\n" + PREFERENCES.dump())
    elif cfg_action == "reset":
        print("\nResetting preferences...")
        reset_preferences()
        save_preferences()
        print("\n" + PREFERENCES.dump())
    elif cfg_action == "save":
        setup(args)
        save_preferences()
        print("\nUpdated Preferences:")
        print("====================")
        print(PREFERENCES.dump())
    else:
        raise AssertionError("cfg_action {} not supported".format(cfg_action))


def handle_process_2d(args):
    """Handle process_2d command.

    Args:
        args (argparse.Namespace): command line arguments.
    """

    setup(args)
    if not PREFERENCES.MODELS_DIR:
        raise ValueError(
            "MODELS_DIR not initialized. "
            "Use `C2C config` to set MODELS_DIR"
        )
    logger = logging.getLogger("Comp2Comp.bin.C2C.__main__")
    logger.info("\n\n======================================================")
    gpus = dl_utils.get_available_gpus(args.num_gpus)
    num_gpus = len(gpus) if gpus is not None else 0
    if gpus is not None:
        os.environ["CUDA_VISIBLE_DEVICES"] = ",".join([str(x) for x in gpus])
    else:
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # cpu

    # Find files.
    dicom_files = []
    f = PREFERENCES.INPUT_PATH
    if not os.path.isdir(f):
        raise ValueError("Input path must be a directory")
    
    dirs = [os.path.abspath(f)]

    dicom_files.extend(
        find_files(
            dirs,
            max_depth=args.max_depth,
            exist_ok=args.overwrite,
            pattern=args.pattern,
        )
    )

    label_text = get_file_names(dicom_files)

    logger.info("{} scans found".format(len(dicom_files)))
    if len(dicom_files) == 0:
        sys.exit(0)

    batch_size = PREFERENCES.BATCH_SIZE
    use_pp = args.pp
    num_workers = PREFERENCES.NUM_WORKERS

    logger.info("Preferences:\n" + PREFERENCES.dump())

    muscle_fat_model_type = Models.model_from_name("stanford_v0.0.1")

    parent_dir = os.path.basename(os.path.dirname(PREFERENCES.INPUT_PATH))
    output_path = Path(os.path.join(PREFERENCES.OUTPUT_PATH, parent_dir))
    output_path.mkdir(parents=True, exist_ok=True)
    output_path = str(output_path)

    # Log the output path
    logger.info("Output path: {}".format(output_path))

    segmentations_path = Path(output_path) / "segmentations"
    segmentations_path.mkdir(parents=True, exist_ok=True)

    (inputs, masks, file_names, model_type) = inference_2d(
        args,
        batch_size,
        use_pp,
        num_workers,
        dicom_files,
        num_gpus,
        logger,
        muscle_fat_model_type,
        label_text,
        output_dir = segmentations_path
    )

    _, manifest = handle_summarize(output_path)

    figure_text_map = metrics.manifest_to_map(manifest)

    # Save images
    for num_2d in range(len(inputs)):
        save_binary_segmentation_overlay(
            inputs[num_2d],
            masks[num_2d],
            output_path,
            f"{file_names[num_2d]}.png",
            figure_text_key=figure_text_map,
            spine = False,
            model_type = muscle_fat_model_type
        )


def handle_process_3d(args):
    """Handle process_3d command.
    
    Args:
        args (argparse.Namespace): command line arguments.

    Raises:
        ValueError: if invalid model type.
    """
    st = time()
    setup(args)
    if not PREFERENCES.MODELS_DIR:
        raise ValueError(
            "MODELS_DIR not initialized. "
            "Use `C2C config` to set MODELS_DIR"
        )
    logger = logging.getLogger("Comp2Comp.bin.C2C.__main__")
    logger.info("\n\n======================================================")

    gpus = dl_utils.get_available_gpus(args.num_gpus)
    num_gpus = len(gpus) if gpus is not None else 0
    if gpus is not None:
        os.environ["CUDA_VISIBLE_DEVICES"] = ",".join([str(x) for x in gpus])
    else:
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    logger.info("Preferences:\n" + PREFERENCES.dump())

    muscle_fat_model_type = Models.model_from_name("stanford_v0.0.1")
    spine_model_type = Models.model_from_name("ts_spine")

    for path, num in get_dicom_paths_and_num(PREFERENCES.INPUT_PATH):
        try:
            logger.info("\n\n======================================================")
            logger.info("Processing the DICOM series from {}".format(path))
            logger.info("======================================================")

            # assert that the number of slices is greater
            # than 300, if not, go to next loop iteration
            if num < 300:
                logger.info("Number of slices is less than 300, skipping")
                continue

            # Get parent directory name not path
            # print("FOR DEBUGGING")
            # print(path)
            # print(os.path.dirname(path))
            # print(os.path.basename(os.path.dirname(path)))
            # parent_dir = os.path.basename(os.path.dirname(path))
            parent_dir = os.path.basename(path)
            output_path = Path(os.path.join(PREFERENCES.OUTPUT_PATH, parent_dir))
            output_path.mkdir(parents=True, exist_ok=True)
            output_path = str(output_path)

            # Log the output path
            logger.info("Output path: {}".format(output_path))

            seg_input_path = path
            segmentations_path = Path(output_path) / "segmentations"
            segmentations_path.mkdir(parents=True, exist_ok=True)
            seg_output_dir = str(segmentations_path / "spine.nii.gz")

            # Perform spine segmentation inference
            seg, mvs = spine_seg(logger, seg_input_path, seg_output_dir)

            (spine_hus, rois, centroids) = spine_utils.compute_rois(
                seg,
                mvs.volume,
                mvs.get_metadata("RescaleSlope"),
                mvs.get_metadata("RescaleIntercept"),
                spine_model_type
            )
            dicom_files, label_text, centroids = spine_utils.find_spine_dicoms(
                seg,
                path,
                spine_model_type
            )
            logger.info("{} scans found".format(len(dicom_files)))
            spine_utils.visualize_coronal_sagittal_spine(
                seg,
                rois,
                mvs,
                centroids,
                label_text,
                output_path,
                spine_hus=spine_hus,
                model_type=spine_model_type
            )

            # Print dicom paths to logger
            logger.info(f"Dicom paths: {dicom_files}")
            batch_size = PREFERENCES.BATCH_SIZE
            use_pp = args.pp
            num_workers = PREFERENCES.NUM_WORKERS
            (inputs, masks, file_names, results) = inference_2d(
                args,
                batch_size,
                use_pp,
                num_workers,
                dicom_files,
                num_gpus,
                logger,
                muscle_fat_model_type,
                label_text,
                segmentations_path
            )

            _, manifest = handle_summarize(output_path, dicom_files, label_text, spine_hus)

            # TODO: this is hacky, but it works. We need to refactor this
            figure_text_map = metrics.manifest_to_map(manifest)

            # Save images
            for num_2d in range(len(inputs)):
                save_binary_segmentation_overlay(
                    inputs[num_2d],
                    masks[num_2d],
                    output_path,
                    f"{file_names[num_2d]}.png",
                    figure_text_key=figure_text_map,
                    model_type=muscle_fat_model_type
                )
            generate_panel(os.path.join(output_path, "images"))
            end = time()

            # Log total time for 3d processing
            logger.info(f"Total time for 3D processing: {end-st:.2f}s.")

        except Exception as e:
            shutil.rmtree(output_path)
            logger.info(f"ERROR PROCESSING {path}")
            logger.info(str(e))
            continue

def handle_summarize(results_dir, dicom_files=None, label_text=None, spine_hus=None):
    """Handle summarize command.

    Args:
        results_dir (str): path to results directory.
        dicom_files (list): list of dicom file paths.
        label_text (list): list of label text.
        spine_hus (list): list of spine hus.

    Returns:
        (str, dict): path to summary file and manifest.
    """
    
    results_dir_sub = Path(results_dir) / "metrics"
    results_dir_sub.mkdir(exist_ok=True)
    metrics_file = os.path.join(results_dir_sub, "c2c-metrics.csv")
    h5_files = sorted(
        find_files(str(Path(results_dir) / "segmentations"),
                   pattern=".*h5$",
                   exist_ok=True)
    )

    manifest = []
    for h5_file in tqdm(h5_files, desc="Parsing metrics"):
        if dicom_files:
            # Get the index of label_text such that the label_text matches the h5_file
            if spine_hus:
                index = [i for i, s in enumerate(label_text) if s in h5_file][0]
                level = label_text[index]
                spine_hu = spine_hus[index]
                dicom_file = dicom_files[index]
            
        with h5py.File(h5_file, "r") as f:
            for model in f.keys():
                scalar_metrics = {}
                for tissue in f[model]:

                    h5_group = f[model][tissue]
                    scalar_metrics.update(
                        {
                            f"{metric} ({tissue})": h5_group[metric][()]
                            for metric in h5_group
                            if not h5_group[metric].shape
                        }
                    )
                if dicom_files and spine_hus:
                    manifest.append(
                        {
                            "Dicom File": dicom_file,
                            "Level": level.split('_')[0],
                            "Model": model,
                            f"Hounsfield Unit (spine roi)": spine_hu,
                            **scalar_metrics
                        }
                    )
                else:
                    manifest.append(
                        {
                            "File": h5_file,
                            "Model": model,
                            **scalar_metrics}
                    )

    df = pd.DataFrame(manifest)
    df.to_csv(metrics_file, index=False)
    return df, manifest


def main():
    args = argument_parser().parse_args()
    if args.action == "config":
        handle_init(args)
    elif args.action == "process_2d":
        handle_process_2d(args)
    elif args.action == "process_3d":
        handle_process_3d(args)
    elif args.action == "summarize":
        handle_summarize(args)
    else:
        raise AssertionError("{} command not supported".format(args.action))


if __name__ == "__main__":
    main()


